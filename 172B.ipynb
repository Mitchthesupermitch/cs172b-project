{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "753130a4-11db-401f-8afc-af35bb68fc98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b060fba2-b3f2-4b7e-9603-920b3fd0a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b53709f9-8c18-4c9e-9a38-324eaeb095cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>Active_Energy_Not_Measured</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:15:00</th>\n",
       "      <td>4.587333</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>234.366667</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>16.833333</td>\n",
       "      <td>58.288889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:30:00</th>\n",
       "      <td>4.140667</td>\n",
       "      <td>0.327733</td>\n",
       "      <td>234.768667</td>\n",
       "      <td>17.773333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>16.866667</td>\n",
       "      <td>51.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:45:00</th>\n",
       "      <td>4.159333</td>\n",
       "      <td>0.028267</td>\n",
       "      <td>234.630000</td>\n",
       "      <td>17.786667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.866667</td>\n",
       "      <td>52.455556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 18:00:00</th>\n",
       "      <td>4.121067</td>\n",
       "      <td>0.152533</td>\n",
       "      <td>235.566000</td>\n",
       "      <td>17.706667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.933333</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>31.751111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 18:15:00</th>\n",
       "      <td>3.768533</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>234.803333</td>\n",
       "      <td>16.226667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>43.008889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power     Voltage  \\\n",
       "Datetime                                                                      \n",
       "2006-12-16 17:15:00             4.587333               0.484000  234.366667   \n",
       "2006-12-16 17:30:00             4.140667               0.327733  234.768667   \n",
       "2006-12-16 17:45:00             4.159333               0.028267  234.630000   \n",
       "2006-12-16 18:00:00             4.121067               0.152533  235.566000   \n",
       "2006-12-16 18:15:00             3.768533               0.017200  234.803333   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "Datetime                                                                \n",
       "2006-12-16 17:15:00         19.700000             0.0        1.333333   \n",
       "2006-12-16 17:30:00         17.773333             0.0        0.733333   \n",
       "2006-12-16 17:45:00         17.786667             0.0        0.000000   \n",
       "2006-12-16 18:00:00         17.706667             0.0       19.933333   \n",
       "2006-12-16 18:15:00         16.226667             0.0        2.866667   \n",
       "\n",
       "                     Sub_metering_3  Active_Energy_Not_Measured  \n",
       "Datetime                                                         \n",
       "2006-12-16 17:15:00       16.833333                   58.288889  \n",
       "2006-12-16 17:30:00       16.866667                   51.411111  \n",
       "2006-12-16 17:45:00       16.866667                   52.455556  \n",
       "2006-12-16 18:00:00       17.000000                   31.751111  \n",
       "2006-12-16 18:15:00       16.933333                   43.008889  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'household_power_consumption.txt'\n",
    "data = pd.read_csv(file_path, sep=';', na_values='?', low_memory=False)\n",
    "\n",
    "# Combine and convert the Date and Time into a single Datetime column and set as index\n",
    "data['Datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'], dayfirst=True)\n",
    "data.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "data.set_index('Datetime', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Impute missing values based on the mean of the same time slot across different years\n",
    "time_mean = data.groupby(data.index.time).mean()\n",
    "for col in ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']:\n",
    "    fill_values = data.index.map(lambda x: time_mean.at[x.time(), col])\n",
    "    data[col] = data[col].fillna(pd.Series(fill_values, index=data.index))\n",
    "\n",
    "# Calculate the new feature 'Active_Energy_Not_Measured'\n",
    "data['Active_Energy_Not_Measured'] = (data['Global_active_power'] * 1000 / 60) - (data['Sub_metering_1'] + data['Sub_metering_2'] + data['Sub_metering_3'])\n",
    "\n",
    "## Resample the dataset to every 15 minutes\n",
    "data_resampled = data.resample('15min').mean()\n",
    "\n",
    "# Display the first few rows of the resampled dataframe to verify\n",
    "data_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f14622e-8aee-4298-9372-6b88e16e8e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 138352 entries, 2006-12-16 17:15:00 to 2010-11-26 21:00:00\n",
      "Freq: 15min\n",
      "Data columns (total 8 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Global_active_power         138352 non-null  float64\n",
      " 1   Global_reactive_power       138352 non-null  float64\n",
      " 2   Voltage                     138352 non-null  float64\n",
      " 3   Global_intensity            138352 non-null  float64\n",
      " 4   Sub_metering_1              138352 non-null  float64\n",
      " 5   Sub_metering_2              138352 non-null  float64\n",
      " 6   Sub_metering_3              138352 non-null  float64\n",
      " 7   Active_Energy_Not_Measured  138352 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 9.5 MB\n"
     ]
    }
   ],
   "source": [
    "data_resampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6964cbd3-64f4-4c9b-96b8-f10b92bf6e5a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 81607 entries, 2007-01-16 17:15:00 to 2009-11-16 17:15:00\n",
      "Data columns (total 8 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Global_active_power         81607 non-null  float64\n",
      " 1   Global_reactive_power       81607 non-null  float64\n",
      " 2   Voltage                     81607 non-null  float64\n",
      " 3   Global_intensity            81607 non-null  float64\n",
      " 4   Sub_metering_1              81607 non-null  float64\n",
      " 5   Sub_metering_2              81607 non-null  float64\n",
      " 6   Sub_metering_3              81607 non-null  float64\n",
      " 7   Active_Energy_Not_Measured  81607 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 5.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets by holding out the last year\n",
    "test_start_date = '2009-12-01'\n",
    "train_data = data_resampled[:test_start_date]\n",
    "test_data = data_resampled[test_start_date:]\n",
    "\n",
    "# For validation, split the remaining training data by holding out one month every five months\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "\n",
    "current_date = train_data.index.min()\n",
    "end_date = train_data.index.max()\n",
    "\n",
    "while current_date <= end_date:\n",
    "    month_start = current_date\n",
    "    month_end = month_start + pd.DateOffset(months=1)\n",
    "    five_month_end = month_start + pd.DateOffset(months=5)\n",
    "    \n",
    "    # Add the indices of the current month to validation, rest to train\n",
    "    month_indices = train_data[month_start:month_end].index\n",
    "    train_month_indices = train_data[month_end:five_month_end].index\n",
    "    \n",
    "    val_indices.extend(month_indices)\n",
    "    train_indices.extend(train_month_indices)\n",
    "    \n",
    "    # Move current date by five months\n",
    "    current_date = five_month_end\n",
    "\n",
    "train_final = train_data.loc[train_indices]\n",
    "val_final = train_data.loc[val_indices]\n",
    "\n",
    "# Scaling the data\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_final.values)\n",
    "val_scaled = scaler.transform(val_final.values)\n",
    "test_scaled = scaler.transform(test_data.values)\n",
    "\n",
    "# Display the first few rows of the resampled dataframe to verify\n",
    "train_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77682658-0c1b-487b-9f04-7f2531497c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i+n_steps, :-1])  # all features except the target\n",
    "        y.append(data[i+n_steps, 0])  # target feature\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Number of time steps to look back\n",
    "n_steps = 96  # corresponds to 1 day (24 hours * 4 intervals per hour)\n",
    "\n",
    "# Create sequences for training, validation, and testing sets\n",
    "X_train, y_train = create_sequences(train_scaled, n_steps)\n",
    "X_val, y_val = create_sequences(val_scaled, n_steps)\n",
    "X_test, y_test = create_sequences(test_scaled, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "543e933b-919e-485b-ac1f-7251647ec07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Epoch 1, Loss: 0.0040953392162919044, Validation Loss: 0.005072918254882097\n",
      "Epoch 1 completed in 12.21 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 2, Loss: 0.0010416405275464058, Validation Loss: 0.0041052247397601604\n",
      "Epoch 2 completed in 11.77 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 3, Loss: 0.00480554299429059, Validation Loss: 0.0038613954093307257\n",
      "Epoch 3 completed in 11.79 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 4, Loss: 0.005062546581029892, Validation Loss: 0.004227539524435997\n",
      "Epoch 4 completed in 11.83 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 5, Loss: 0.003094468731433153, Validation Loss: 0.0037207792047411203\n",
      "Epoch 5 completed in 11.82 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 6, Loss: 0.003807675326243043, Validation Loss: 0.005115846171975136\n",
      "Epoch 6 completed in 11.88 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 7, Loss: 0.0030123370233923197, Validation Loss: 0.004072390031069517\n",
      "Epoch 7 completed in 12.10 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 8, Loss: 0.00530029134824872, Validation Loss: 0.0039119110442698\n",
      "Epoch 8 completed in 11.74 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 9, Loss: 0.007201445288956165, Validation Loss: 0.0038557008374482393\n",
      "Epoch 9 completed in 11.81 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 10, Loss: 0.005568953696638346, Validation Loss: 0.004265328869223595\n",
      "Epoch 10 completed in 11.82 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 11, Loss: 0.0028173995669931173, Validation Loss: 0.0038008501287549734\n",
      "Epoch 11 completed in 11.79 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 12, Loss: 0.003943044692277908, Validation Loss: 0.004127069376409054\n",
      "Epoch 12 completed in 11.81 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 13, Loss: 0.00358924875035882, Validation Loss: 0.003951466176658869\n",
      "Epoch 13 completed in 11.85 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 14, Loss: 0.0025271798949688673, Validation Loss: 0.003929642029106617\n",
      "Epoch 14 completed in 11.81 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 15, Loss: 0.004373473115265369, Validation Loss: 0.0050996895879507065\n",
      "Epoch 15 completed in 11.76 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 16, Loss: 0.006222625263035297, Validation Loss: 0.004281794652342796\n",
      "Epoch 16 completed in 12.07 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 17, Loss: 0.0027001111302524805, Validation Loss: 0.0038159231189638376\n",
      "Epoch 17 completed in 11.92 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 18, Loss: 0.002796073677018285, Validation Loss: 0.004190337844192982\n",
      "Epoch 18 completed in 11.73 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 19, Loss: 0.004902746994048357, Validation Loss: 0.004329309333115816\n",
      "Epoch 19 completed in 11.74 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 20, Loss: 0.0019434252753853798, Validation Loss: 0.0052085635252296925\n",
      "Epoch 20 completed in 11.80 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 21, Loss: 0.009531620889902115, Validation Loss: 0.005611604079604149\n",
      "Epoch 21 completed in 12.52 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 22, Loss: 0.0036168836522847414, Validation Loss: 0.003953607752919197\n",
      "Epoch 22 completed in 12.08 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 23, Loss: 0.004912428092211485, Validation Loss: 0.004448538646101952\n",
      "Epoch 23 completed in 12.34 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 24, Loss: 0.003921904601156712, Validation Loss: 0.004644002765417099\n",
      "Epoch 24 completed in 12.46 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 25, Loss: 0.010474559850990772, Validation Loss: 0.00550371129065752\n",
      "Epoch 25 completed in 12.48 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 26, Loss: 0.0030103514436632395, Validation Loss: 0.004377587232738733\n",
      "Epoch 26 completed in 11.83 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 27, Loss: 0.0075478823855519295, Validation Loss: 0.004178439266979694\n",
      "Epoch 27 completed in 11.84 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 28, Loss: 0.0029065245762467384, Validation Loss: 0.00400244165211916\n",
      "Epoch 28 completed in 12.52 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 29, Loss: 0.0026603180449455976, Validation Loss: 0.00443506333976984\n",
      "Epoch 29 completed in 12.45 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Epoch 30, Loss: 0.004465451464056969, Validation Loss: 0.004684603773057461\n",
      "Epoch 30 completed in 11.90 seconds\n",
      "----------------------------------------------------------------------------\n",
      "Test RMSE: 0.0642034038901329, Test MAE: 0.04820014163851738\n"
     ]
    }
   ],
   "source": [
    "# Check for MPS availability and set the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim, device=x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim, device=x.device)\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Assume X_train, y_train, X_val, y_val, X_test, y_test are already defined\n",
    "\n",
    "# Convert to PyTorch tensors without specifying device here\n",
    "train_features = torch.Tensor(X_train)\n",
    "train_targets = torch.Tensor(y_train)\n",
    "val_features = torch.Tensor(X_val)\n",
    "val_targets = torch.Tensor(y_val)\n",
    "test_features = torch.Tensor(X_test)\n",
    "test_targets = torch.Tensor(y_test)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(TensorDataset(train_features, train_targets), batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LSTMModel(input_dim=train_features.shape[2], hidden_dim=20, num_layers=2, output_dim=1).to(device) # hidDIm - 20\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    start_time_epoch = time.time()  # Start time for the epoch\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_features, val_targets = val_features.to(device), val_targets.to(device)\n",
    "        val_predictions = model(val_features)\n",
    "        val_loss = criterion(val_predictions, val_targets.view(-1, 1))\n",
    "\n",
    "    end_time_epoch = time.time()  # End time for the epoch\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}')\n",
    "    print(f'Epoch {epoch+1} completed in {end_time_epoch - start_time_epoch:.2f} seconds')\n",
    "    print(f'----------------------------------------------------------------------------')\n",
    "\n",
    "# Evaluate on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_features, test_targets = test_features.to(device), test_targets.to(device)\n",
    "    predictions = model(test_features)\n",
    "    test_loss = criterion(predictions, test_targets.view(-1, 1))\n",
    "\n",
    "# Calculate RMSE and MAE\n",
    "rmse = np.sqrt(mean_squared_error(test_targets.cpu().numpy(), predictions.cpu().numpy()))\n",
    "mae = mean_absolute_error(test_targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "print(f'Test RMSE: {rmse}, Test MAE: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c276233-8e9f-4d7e-b30c-ad6353b521dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
